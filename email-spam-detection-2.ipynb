{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eefbb729",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-01-29T20:43:10.170185Z",
     "iopub.status.busy": "2024-01-29T20:43:10.169802Z",
     "iopub.status.idle": "2024-01-29T20:43:12.651969Z",
     "shell.execute_reply": "2024-01-29T20:43:12.650162Z"
    },
    "papermill": {
     "duration": 2.491046,
     "end_time": "2024-01-29T20:43:12.655225",
     "exception": false,
     "start_time": "2024-01-29T20:43:10.164179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50e822a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-29T20:43:12.666077Z",
     "iopub.status.busy": "2024-01-29T20:43:12.664888Z",
     "iopub.status.idle": "2024-01-29T20:43:37.813449Z",
     "shell.execute_reply": "2024-01-29T20:43:37.811801Z"
    },
    "papermill": {
     "duration": 25.156853,
     "end_time": "2024-01-29T20:43:37.816216",
     "exception": false,
     "start_time": "2024-01-29T20:43:12.659363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "enron_data = pd.read_csv('C:\\\\Users\\m_aminan\\Downloads\\emails.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ff3fd77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-29T20:43:37.825659Z",
     "iopub.status.busy": "2024-01-29T20:43:37.825279Z",
     "iopub.status.idle": "2024-01-29T20:43:37.841652Z",
     "shell.execute_reply": "2024-01-29T20:43:37.840192Z"
    },
    "papermill": {
     "duration": 0.023712,
     "end_time": "2024-01-29T20:43:37.843927",
     "exception": false,
     "start_time": "2024-01-29T20:43:37.820215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       file                                            message\n",
      "0     allen-p/_sent_mail/1.  Message-ID: <18782981.1075855378110.JavaMail.e...\n",
      "1    allen-p/_sent_mail/10.  Message-ID: <15464986.1075855378456.JavaMail.e...\n",
      "2   allen-p/_sent_mail/100.  Message-ID: <24216240.1075855687451.JavaMail.e...\n",
      "3  allen-p/_sent_mail/1000.  Message-ID: <13505866.1075863688222.JavaMail.e...\n",
      "4  allen-p/_sent_mail/1001.  Message-ID: <30922949.1075863688243.JavaMail.e...\n"
     ]
    }
   ],
   "source": [
    "print(enron_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d44297e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-29T20:43:37.852894Z",
     "iopub.status.busy": "2024-01-29T20:43:37.852479Z",
     "iopub.status.idle": "2024-01-29T20:43:37.981648Z",
     "shell.execute_reply": "2024-01-29T20:43:37.979822Z"
    },
    "papermill": {
     "duration": 0.13739,
     "end_time": "2024-01-29T20:43:37.985008",
     "exception": false,
     "start_time": "2024-01-29T20:43:37.847618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517401 entries, 0 to 517400\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   file     517401 non-null  object\n",
      " 1   message  517401 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 7.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(enron_data.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50230059",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-29T20:43:37.993837Z",
     "iopub.status.busy": "2024-01-29T20:43:37.993439Z",
     "iopub.status.idle": "2024-01-29T20:43:39.662894Z",
     "shell.execute_reply": "2024-01-29T20:43:39.660920Z"
    },
    "papermill": {
     "duration": 1.677284,
     "end_time": "2024-01-29T20:43:39.665931",
     "exception": false,
     "start_time": "2024-01-29T20:43:37.988647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         file  \\\n",
      "count                  517401   \n",
      "unique                 517401   \n",
      "top     allen-p/_sent_mail/1.   \n",
      "freq                        1   \n",
      "\n",
      "                                                  message  \n",
      "count                                              517401  \n",
      "unique                                             517401  \n",
      "top     Message-ID: <18782981.1075855378110.JavaMail.e...  \n",
      "freq                                                    1  \n"
     ]
    }
   ],
   "source": [
    "print(enron_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "528e0181",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-29T20:43:39.675220Z",
     "iopub.status.busy": "2024-01-29T20:43:39.674801Z",
     "iopub.status.idle": "2024-01-29T20:43:39.778616Z",
     "shell.execute_reply": "2024-01-29T20:43:39.776536Z"
    },
    "papermill": {
     "duration": 0.111464,
     "end_time": "2024-01-29T20:43:39.781145",
     "exception": false,
     "start_time": "2024-01-29T20:43:39.669681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file       0\n",
      "message    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(enron_data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcf41efe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-29T20:43:39.790003Z",
     "iopub.status.busy": "2024-01-29T20:43:39.789605Z",
     "iopub.status.idle": "2024-01-29T20:43:39.795957Z",
     "shell.execute_reply": "2024-01-29T20:43:39.794330Z"
    },
    "papermill": {
     "duration": 0.013468,
     "end_time": "2024-01-29T20:43:39.798302",
     "exception": false,
     "start_time": "2024-01-29T20:43:39.784834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message-ID: <18782981.1075855378110.JavaMail.evans@thyme>\n",
      "Date: Mon, 14 May 2001 16:39:00 -0700 (PDT)\n",
      "From: phillip.allen@enron.com\n",
      "To: tim.belden@enron.com\n",
      "Subject: \n",
      "Mime-Version: 1.0\n",
      "Content-Type: text/plain; charset=us-ascii\n",
      "Content-Transfer-Encoding: 7bit\n",
      "X-From: Phillip K Allen\n",
      "X-To: Tim Belden <Tim Belden/Enron@EnronXGate>\n",
      "X-cc: \n",
      "X-bcc: \n",
      "X-Folder: \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Sent Mail\n",
      "X-Origin: Allen-P\n",
      "X-FileName: pallen (Non-Privileged).pst\n",
      "\n",
      "Here is our forecast\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(enron_data['message'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ffc3028",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-29T20:43:39.807152Z",
     "iopub.status.busy": "2024-01-29T20:43:39.806787Z",
     "iopub.status.idle": "2024-01-29T20:43:39.814186Z",
     "shell.execute_reply": "2024-01-29T20:43:39.813149Z"
    },
    "papermill": {
     "duration": 0.01405,
     "end_time": "2024-01-29T20:43:39.816151",
     "exception": false,
     "start_time": "2024-01-29T20:43:39.802101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import email\n",
    "from email.parser import Parser\n",
    "\n",
    "def parse_email(text):\n",
    "    # Parse the email content\n",
    "    msg = email.message_from_string(text)\n",
    "\n",
    "    # Extract headers\n",
    "    from_ = msg['from']\n",
    "    to_ = msg['to']\n",
    "    subject_ = msg['subject']\n",
    "\n",
    "    # Get email body\n",
    "    if msg.is_multipart():\n",
    "        for part in msg.walk():\n",
    "            if part.get_content_type() == 'text/plain':\n",
    "                body = part.get_payload(decode=True).decode('utf-8', errors='ignore')\n",
    "                break\n",
    "    else:\n",
    "        body = msg.get_payload(decode=True).decode('utf-8', errors='ignore')\n",
    "\n",
    "    return {'from': from_, 'to': to_, 'subject': subject_, 'body': body}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d917fca4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-29T20:43:39.825926Z",
     "iopub.status.busy": "2024-01-29T20:43:39.825012Z",
     "iopub.status.idle": "2024-01-29T20:44:47.106639Z",
     "shell.execute_reply": "2024-01-29T20:44:47.105230Z"
    },
    "papermill": {
     "duration": 67.289041,
     "end_time": "2024-01-29T20:44:47.109168",
     "exception": false,
     "start_time": "2024-01-29T20:43:39.820127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply the parsing function to each email message\n",
    "parsed_emails = enron_data['message'].apply(parse_email)\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "parsed_emails_df = pd.DataFrame(list(parsed_emails))\n",
    "\n",
    "# Concatenate with the original DataFrame\n",
    "enron_data = pd.concat([enron_data, parsed_emails_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ac3dcd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-29T20:44:47.118029Z",
     "iopub.status.busy": "2024-01-29T20:44:47.117633Z",
     "iopub.status.idle": "2024-01-29T20:44:47.220089Z",
     "shell.execute_reply": "2024-01-29T20:44:47.218650Z"
    },
    "papermill": {
     "duration": 0.109658,
     "end_time": "2024-01-29T20:44:47.222601",
     "exception": false,
     "start_time": "2024-01-29T20:44:47.112943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       file  \\\n",
      "0     allen-p/_sent_mail/1.   \n",
      "1    allen-p/_sent_mail/10.   \n",
      "2   allen-p/_sent_mail/100.   \n",
      "3  allen-p/_sent_mail/1000.   \n",
      "4  allen-p/_sent_mail/1001.   \n",
      "\n",
      "                                             message                     from  \\\n",
      "0  Message-ID: <18782981.1075855378110.JavaMail.e...  phillip.allen@enron.com   \n",
      "1  Message-ID: <15464986.1075855378456.JavaMail.e...  phillip.allen@enron.com   \n",
      "2  Message-ID: <24216240.1075855687451.JavaMail.e...  phillip.allen@enron.com   \n",
      "3  Message-ID: <13505866.1075863688222.JavaMail.e...  phillip.allen@enron.com   \n",
      "4  Message-ID: <30922949.1075863688243.JavaMail.e...  phillip.allen@enron.com   \n",
      "\n",
      "                        to    subject  \\\n",
      "0     tim.belden@enron.com              \n",
      "1  john.lavorato@enron.com        Re:   \n",
      "2   leah.arsdall@enron.com   Re: test   \n",
      "3    randall.gay@enron.com              \n",
      "4     greg.piper@enron.com  Re: Hello   \n",
      "\n",
      "                                                body  \n",
      "0                          Here is our forecast\\n\\n   \n",
      "1  Traveling to have a business meeting takes the...  \n",
      "2                     test successful.  way to go!!!  \n",
      "3  Randy,\\n\\n Can you send me a schedule of the s...  \n",
      "4                Let's shoot for Tuesday at 11:45.    \n",
      "---------------------------------------------------\n",
      "from\n",
      "kay.mann@enron.com                  16735\n",
      "vince.kaminski@enron.com            14368\n",
      "jeff.dasovich@enron.com             11411\n",
      "pete.davis@enron.com                 9149\n",
      "chris.germany@enron.com              8801\n",
      "                                    ...  \n",
      "jnissl@healthwise.org                   1\n",
      "wickedbill@yahoo.com                    1\n",
      "kathleen_corcoran@holderness.org        1\n",
      "katrinadvl@aol.com                      1\n",
      "ingjald@shaw.ca                         1\n",
      "Name: count, Length: 20328, dtype: int64\n",
      "---------------------------------------------------\n",
      "0             \n",
      "1          Re:\n",
      "2     Re: test\n",
      "3             \n",
      "4    Re: Hello\n",
      "Name: subject, dtype: object\n",
      "0                            Here is our forecast\\n\\n \n",
      "1    Traveling to have a business meeting takes the...\n",
      "2                       test successful.  way to go!!!\n",
      "3    Randy,\\n\\n Can you send me a schedule of the s...\n",
      "4                  Let's shoot for Tuesday at 11:45.  \n",
      "Name: body, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the new DataFrame\n",
    "print(enron_data.head())\n",
    "print(\"---------------------------------------------------\")\n",
    "\n",
    "# Explore the distribution of emails sent from different addresses\n",
    "print(enron_data['from'].value_counts())\n",
    "print(\"---------------------------------------------------\")\n",
    "\n",
    "\n",
    "# Basic EDA on the subject and body of the emails\n",
    "print(enron_data['subject'].head())\n",
    "print(enron_data['body'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4862eab9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-29T20:44:47.232838Z",
     "iopub.status.busy": "2024-01-29T20:44:47.232175Z",
     "iopub.status.idle": "2024-01-29T20:44:47.238741Z",
     "shell.execute_reply": "2024-01-29T20:44:47.237226Z"
    },
    "papermill": {
     "duration": 0.014876,
     "end_time": "2024-01-29T20:44:47.241392",
     "exception": false,
     "start_time": "2024-01-29T20:44:47.226516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuations and numbers\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    # Remove single character terms\n",
    "    text = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', text)\n",
    "    # Remove multiple spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b4db42d",
   "metadata": {
    "papermill": {
     "duration": 0.003589,
     "end_time": "2024-01-29T20:44:47.248964",
     "exception": false,
     "start_time": "2024-01-29T20:44:47.245375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "enron_data['cleaned_subject'] = enron_data['subject'].apply(clean_text)\n",
    "enron_data['cleaned_body'] = enron_data['body'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ae8c284",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\m_aminan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\m_aminan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load stopwords once\n",
    "english_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def tokenize_and_remove_stopwords(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered_tokens = [word for word in tokens if word not in english_stopwords]\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "# Apply the function\n",
    "enron_data['processed_subject'] = enron_data['cleaned_subject'].apply(tokenize_and_remove_stopwords)\n",
    "enron_data['processed_body'] = enron_data['cleaned_body'].apply(tokenize_and_remove_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "760351db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  processed_subject                                     processed_body\n",
      "0                                                             forecast\n",
      "1                    traveling business meeting takes fun trip espe...\n",
      "2              test                             test successful way go\n",
      "3                    randy send schedule salary level everyone sche...\n",
      "4             hello                                  let shoot tuesday\n"
     ]
    }
   ],
   "source": [
    "print(enron_data[['processed_subject', 'processed_body']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1f4fe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # You can adjust 'max_features' as needed\n",
    "\n",
    "# Apply it to both subjects and bodies of emails\n",
    "tfidf_subject = tfidf_vectorizer.fit_transform(enron_data['processed_subject'])\n",
    "tfidf_body = tfidf_vectorizer.fit_transform(enron_data['processed_body'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3e3008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_subject_df = pd.DataFrame(tfidf_subject.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "tfidf_body_df = pd.DataFrame(tfidf_body.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d71a8035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate with the original DataFrame (if needed)\n",
    "enron_data = pd.concat([enron_data, tfidf_subject_df, tfidf_body_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "126a4425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       file  \\\n",
      "0     allen-p/_sent_mail/1.   \n",
      "1    allen-p/_sent_mail/10.   \n",
      "2   allen-p/_sent_mail/100.   \n",
      "3  allen-p/_sent_mail/1000.   \n",
      "4  allen-p/_sent_mail/1001.   \n",
      "\n",
      "                                             message                     from  \\\n",
      "0  Message-ID: <18782981.1075855378110.JavaMail.e...  phillip.allen@enron.com   \n",
      "1  Message-ID: <15464986.1075855378456.JavaMail.e...  phillip.allen@enron.com   \n",
      "2  Message-ID: <24216240.1075855687451.JavaMail.e...  phillip.allen@enron.com   \n",
      "3  Message-ID: <13505866.1075863688222.JavaMail.e...  phillip.allen@enron.com   \n",
      "4  Message-ID: <30922949.1075863688243.JavaMail.e...  phillip.allen@enron.com   \n",
      "\n",
      "                        to    subject  \\\n",
      "0     tim.belden@enron.com              \n",
      "1  john.lavorato@enron.com        Re:   \n",
      "2   leah.arsdall@enron.com   Re: test   \n",
      "3    randall.gay@enron.com              \n",
      "4     greg.piper@enron.com  Re: Hello   \n",
      "\n",
      "                                                body cleaned_subject  \\\n",
      "0                          Here is our forecast\\n\\n                    \n",
      "1  Traveling to have a business meeting takes the...             re    \n",
      "2                     test successful.  way to go!!!         re test   \n",
      "3  Randy,\\n\\n Can you send me a schedule of the s...                   \n",
      "4                Let's shoot for Tuesday at 11:45.          re hello   \n",
      "\n",
      "                                        cleaned_body processed_subject  \\\n",
      "0                              here is our forecast                      \n",
      "1  traveling to have business meeting takes the f...                     \n",
      "2                         test successful way to go               test   \n",
      "3  randy can you send me schedule of the salary a...                     \n",
      "4                          let shoot for tuesday at              hello   \n",
      "\n",
      "                                      processed_body  ...     would  www  xls  \\\n",
      "0                                           forecast  ...  0.000000  0.0  0.0   \n",
      "1  traveling business meeting takes fun trip espe...  ...  0.251728  0.0  0.0   \n",
      "2                             test successful way go  ...  0.000000  0.0  0.0   \n",
      "3  randy send schedule salary level everyone sche...  ...  0.000000  0.0  0.0   \n",
      "4                                  let shoot tuesday  ...  0.000000  0.0  0.0   \n",
      "\n",
      "   yahoo  year  years  yes  yesterday  yet  york  \n",
      "0    0.0   0.0    0.0  0.0        0.0  0.0   0.0  \n",
      "1    0.0   0.0    0.0  0.0        0.0  0.0   0.0  \n",
      "2    0.0   0.0    0.0  0.0        0.0  0.0   0.0  \n",
      "3    0.0   0.0    0.0  0.0        0.0  0.0   0.0  \n",
      "4    0.0   0.0    0.0  0.0        0.0  0.0   0.0  \n",
      "\n",
      "[5 rows x 2010 columns]\n"
     ]
    }
   ],
   "source": [
    "print(enron_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "97340220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['file', 'message', 'from', 'to', 'subject', 'body', 'cleaned_subject',\n",
      "       'cleaned_body', 'processed_subject', 'processed_body',\n",
      "       ...\n",
      "       'would', 'www', 'xls', 'yahoo', 'year', 'years', 'yes', 'yesterday',\n",
      "       'yet', 'york'],\n",
      "      dtype='object', length=2010)\n"
     ]
    }
   ],
   "source": [
    "print(enron_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20220ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Example: Applying K-Means to the TF-IDF features\n",
    "text_data = enron_data['processed_body']  # or enron_data['processed_subject']\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "525cdd1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m_aminan\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "clusters = kmeans.fit_predict(tfidf_matrix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "058ac7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       file  \\\n",
      "0     allen-p/_sent_mail/1.   \n",
      "1    allen-p/_sent_mail/10.   \n",
      "2   allen-p/_sent_mail/100.   \n",
      "3  allen-p/_sent_mail/1000.   \n",
      "4  allen-p/_sent_mail/1001.   \n",
      "\n",
      "                                             message                     from  \\\n",
      "0  Message-ID: <18782981.1075855378110.JavaMail.e...  phillip.allen@enron.com   \n",
      "1  Message-ID: <15464986.1075855378456.JavaMail.e...  phillip.allen@enron.com   \n",
      "2  Message-ID: <24216240.1075855687451.JavaMail.e...  phillip.allen@enron.com   \n",
      "3  Message-ID: <13505866.1075863688222.JavaMail.e...  phillip.allen@enron.com   \n",
      "4  Message-ID: <30922949.1075863688243.JavaMail.e...  phillip.allen@enron.com   \n",
      "\n",
      "                        to    subject  \\\n",
      "0     tim.belden@enron.com              \n",
      "1  john.lavorato@enron.com        Re:   \n",
      "2   leah.arsdall@enron.com   Re: test   \n",
      "3    randall.gay@enron.com              \n",
      "4     greg.piper@enron.com  Re: Hello   \n",
      "\n",
      "                                                body cleaned_subject  \\\n",
      "0                          Here is our forecast\\n\\n                    \n",
      "1  Traveling to have a business meeting takes the...             re    \n",
      "2                     test successful.  way to go!!!         re test   \n",
      "3  Randy,\\n\\n Can you send me a schedule of the s...                   \n",
      "4                Let's shoot for Tuesday at 11:45.          re hello   \n",
      "\n",
      "                                        cleaned_body processed_subject  \\\n",
      "0                              here is our forecast                      \n",
      "1  traveling to have business meeting takes the f...                     \n",
      "2                         test successful way to go               test   \n",
      "3  randy can you send me schedule of the salary a...                     \n",
      "4                          let shoot for tuesday at              hello   \n",
      "\n",
      "                                      processed_body  ...  www  xls  yahoo  \\\n",
      "0                                           forecast  ...  0.0  0.0    0.0   \n",
      "1  traveling business meeting takes fun trip espe...  ...  0.0  0.0    0.0   \n",
      "2                             test successful way go  ...  0.0  0.0    0.0   \n",
      "3  randy send schedule salary level everyone sche...  ...  0.0  0.0    0.0   \n",
      "4                                  let shoot tuesday  ...  0.0  0.0    0.0   \n",
      "\n",
      "   year  years  yes  yesterday  yet  york  cluster  \n",
      "0   0.0    0.0  0.0        0.0  0.0   0.0        0  \n",
      "1   0.0    0.0  0.0        0.0  0.0   0.0        0  \n",
      "2   0.0    0.0  0.0        0.0  0.0   0.0        0  \n",
      "3   0.0    0.0  0.0        0.0  0.0   0.0        0  \n",
      "4   0.0    0.0  0.0        0.0  0.0   0.0        0  \n",
      "\n",
      "[5 rows x 2011 columns]\n"
     ]
    }
   ],
   "source": [
    "# Add the cluster labels to your dataframe\n",
    "enron_data['cluster'] = clusters\n",
    "\n",
    "# Inspect a few emails from each cluster\n",
    "print(enron_data[enron_data['cluster'] == 0].head())  # Change 0 to 1, 2, etc. for other clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "99171ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: [('com', 1278636), ('enron', 1235099), ('please', 327547), ('http', 326603), ('subject', 321474), ('pm', 308480), ('energy', 304003), ('power', 297275), ('would', 293812), ('new', 260634)]\n",
      "Cluster 1: [('ect', 1013368), ('enron', 633207), ('hou', 490812), ('subject', 125587), ('corp', 123684), ('cc', 122286), ('pm', 108772), ('ees', 92478), ('na', 79373), ('com', 72053)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_top_terms(data, cluster_number, num_terms=10):\n",
    "    # Filter data for the specified cluster\n",
    "    cluster_data = data[data['cluster'] == cluster_number]\n",
    "    \n",
    "    # Combine all text in the cluster\n",
    "    all_text = ' '.join(cluster_data['processed_body'])  # Assuming 'processed_body' is the column with text data\n",
    "    \n",
    "    # Tokenize and count word frequency\n",
    "    word_list = all_text.split()\n",
    "    word_freq = Counter(word_list)\n",
    "    \n",
    "    # Get the most common terms\n",
    "    common_terms = word_freq.most_common(num_terms)\n",
    "    \n",
    "    return common_terms\n",
    "\n",
    "\n",
    "\n",
    "# Adjust 'num_clusters' to match the number of clusters you have\n",
    "num_clusters = 2  # Example for 2 clusters\n",
    "\n",
    "for cluster_num in range(num_clusters):\n",
    "    print(f\"Cluster {cluster_num}: {get_top_terms(enron_data, cluster_num)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "861c16ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 Sample Emails:\n",
      "                                                  message  message   message\n",
      "28526   Message-ID: <6909344.1075855873255.JavaMail.ev...      0.0  0.000000\n",
      "187624  Message-ID: <24176954.1075847303095.JavaMail.e...      0.0  0.000000\n",
      "368556  Message-ID: <23495623.1075852106674.JavaMail.e...      0.0  0.000000\n",
      "436209  Message-ID: <22626670.1075862247543.JavaMail.e...      0.0  0.137718\n",
      "185898  Message-ID: <30564396.1075847041114.JavaMail.e...      0.0  0.135062\n",
      "Cluster 1 Sample Emails:\n",
      "                                                  message  message  message\n",
      "428543  Message-ID: <8349842.1075844527434.JavaMail.ev...      0.0      0.0\n",
      "111326  Message-ID: <27302301.1075854327156.JavaMail.e...      0.0      0.0\n",
      "301166  Message-ID: <4388697.1075846092676.JavaMail.ev...      0.0      0.0\n",
      "195444  Message-ID: <33446796.1075847182975.JavaMail.e...      0.0      0.0\n",
      "327178  Message-ID: <412513.1075843902241.JavaMail.eva...      0.0      0.0\n"
     ]
    }
   ],
   "source": [
    "# Review a sample of emails from each cluster\n",
    "for cluster_num in range(num_clusters):\n",
    "    print(f\"Cluster {cluster_num} Sample Emails:\")\n",
    "    sample_emails = enron_data[enron_data['cluster'] == cluster_num]['message'].sample(5)\n",
    "    print(sample_emails)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9b8d59b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\m_aminan\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms for 2 clusters:\n",
      "Cluster 0: [('com', 1278636), ('enron', 1235099), ('please', 327547), ('http', 326603), ('subject', 321474), ('pm', 308480), ('energy', 304003), ('power', 297275), ('would', 293812), ('new', 260634)]\n",
      "Cluster 1: [('ect', 1013368), ('enron', 633207), ('hou', 490812), ('subject', 125587), ('corp', 123684), ('cc', 122286), ('pm', 108772), ('ees', 92478), ('na', 79373), ('com', 72053)]\n",
      "Top terms for 3 clusters:\n",
      "Cluster 0: [('com', 1278636), ('enron', 1235099), ('please', 327547), ('http', 326603), ('subject', 321474), ('pm', 308480), ('energy', 304003), ('power', 297275), ('would', 293812), ('new', 260634)]\n",
      "Cluster 1: [('ect', 1013368), ('enron', 633207), ('hou', 490812), ('subject', 125587), ('corp', 123684), ('cc', 122286), ('pm', 108772), ('ees', 92478), ('na', 79373), ('com', 72053)]\n",
      "Cluster 2: []\n",
      "Top terms for 4 clusters:\n",
      "Cluster 0: [('com', 1278636), ('enron', 1235099), ('please', 327547), ('http', 326603), ('subject', 321474), ('pm', 308480), ('energy', 304003), ('power', 297275), ('would', 293812), ('new', 260634)]\n",
      "Cluster 1: [('ect', 1013368), ('enron', 633207), ('hou', 490812), ('subject', 125587), ('corp', 123684), ('cc', 122286), ('pm', 108772), ('ees', 92478), ('na', 79373), ('com', 72053)]\n",
      "Cluster 2: []\n",
      "Cluster 3: []\n"
     ]
    }
   ],
   "source": [
    "# Experiment with different numbers of clusters\n",
    "for k in range(2, 5):  # Trying with 2, 3, and 4 clusters\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    clusters = kmeans.fit_predict(tfidf_matrix)\n",
    "    print(f\"Top terms for {k} clusters:\")\n",
    "    for cluster_num in range(k):\n",
    "        print(f\"Cluster {cluster_num}: {get_top_terms(enron_data, cluster_num)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a4ff6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"kir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f560bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 55,
     "sourceId": 120,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30635,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 102.017537,
   "end_time": "2024-01-29T20:44:48.276020",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-29T20:43:06.258483",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
